{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tom and Jerry Image Classification\n",
    "https://www.kaggle.com/datasets/balabaskar/tom-and-jerry-image-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to extract features of an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow ResNet function to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\n",
    "\n",
    "\n",
    "image_size = (224, 224)\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "# Function to extract features from an image using a pre-trained CNN model\n",
    "def extract_resnet_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    image = resnet_preprocess_input(image)\n",
    "    features = resnet_model.predict(np.expand_dims(image, axis=0))\n",
    "    flattened_features = features.flatten()  \n",
    "    return flattened_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert the image to grayscale (unsigned integer type)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the average RGB values\n",
    "    average_rgb = np.mean(image_rgb, axis=(0, 1))\n",
    "    \n",
    "    # Extract \n",
    "    features = extract_resnet_features(image_path)\n",
    "    # Calculate the pixel percentage matching the color of Tom and Jerry\n",
    "    # Calculate the percentage of pixels in the image that match the color of Tom or Jerry\n",
    "    tom_color_1 = np.array([191, 185, 183])  # Tom's characteristic color 1\n",
    "    tom_color_2 = np.array([142, 54, 69])    # Tom's characteristic color 2\n",
    "    tom_color_3 = np.array([236, 232, 44])   # Tom's characteristic color 3\n",
    "    tom_color_4 = np.array([190, 0, 1])      # Tom's characteristic color 4\n",
    "    jerry_color_1 = np.array([193, 131, 97])  # Jerry's characteristic color 1\n",
    "    jerry_color_2 = np.array([173, 77, 65])   # Jerry's characteristic color 2\n",
    "    jerry_color_3 = np.array([243, 227, 239]) # Jerry's characteristic color 3\n",
    "    \n",
    "    # Calculate the mask for pixels matching the color of Tom or Jerry\n",
    "    tom_mask = np.any(np.isclose(image_rgb, tom_color_1, atol=20), axis=-1) \\\n",
    "               | np.any(np.isclose(image_rgb, tom_color_2, atol=5), axis=-1) \\\n",
    "               | np.any(np.isclose(image_rgb, tom_color_3, atol=5), axis=-1) \\\n",
    "               | np.any(np.isclose(image_rgb, tom_color_4, atol=10), axis=-1)\n",
    "    jerry_mask = np.any(np.isclose(image_rgb, jerry_color_1, atol=20), axis=-1) \\\n",
    "                 | np.any(np.isclose(image_rgb, jerry_color_2, atol=4), axis=-1) \\\n",
    "                 | np.any(np.isclose(image_rgb, jerry_color_3, atol=4), axis=-1)\n",
    "    \n",
    "    tom_pixel_percentage = np.mean(tom_mask)\n",
    "    jerry_pixel_percentage = np.mean(jerry_mask) \n",
    "    \n",
    "    # Return the extracted features\n",
    "    return {\n",
    "        'Image_Path': image_path,\n",
    "        'Average_Red': average_rgb[0],  # Red component\n",
    "        'Average_Green': average_rgb[1],  # Green component\n",
    "        'Average_Blue': average_rgb[2],  # Blue component\n",
    "        'Tom_Pixel_Percentage': tom_pixel_percentage,\n",
    "        'Jerry_Pixel_Percentage': jerry_pixel_percentage,\n",
    "        **{'ResNet_Feature_'+str(i): f for i, f in enumerate(features)},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data_dir and image_size\n",
    "data_dir = './kaggle/input/tom_and_jerry/tom_and_jerry'\n",
    "\n",
    "data = []\n",
    "data_ = []\n",
    "labels = []\n",
    "labels_ = []\n",
    "\n",
    "subfolders = ['jerry', 'tom', 'tom_jerry_0', 'tom_jerry_1']\n",
    "\n",
    "label_categories = {\n",
    "    0: \"Jerry\",\n",
    "    1: \"Tom\",\n",
    "    2: \"None\",\n",
    "    3: \"Both\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_testing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "# Set the maximum number of iterations per subfolder\n",
    "if do_testing: \n",
    "    max_iterations_per_subfolder = 15\n",
    "\n",
    "    data_train_dir = os.path.join(data_dir, 'train')\n",
    "    counter = 0  # Initialize counter\n",
    "\n",
    "    for label, subfolder in enumerate(subfolders):\n",
    "        folder_path = os.path.join(data_train_dir, subfolder)\n",
    "        image_files = os.listdir(folder_path)\n",
    "        \n",
    "        # Reset the counter for each subfolder\n",
    "        counter_per_subfolder = 0  \n",
    "        \n",
    "        for image_file in image_files:\n",
    "            # Check if the maximum number of iterations per subfolder has been reached\n",
    "            if counter_per_subfolder >= max_iterations_per_subfolder:\n",
    "                break  # Exit the loop for the current subfolder\n",
    "            \n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            try:\n",
    "                image_info = extract_features(image_path)\n",
    "                # Add image info and label to lists\n",
    "                data.append(image_info)\n",
    "                labels.append(label)\n",
    "                counter += 1  # Increment the total counter\n",
    "                counter_per_subfolder += 1  # Increment the counter for the current subfolder\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df_train = pd.DataFrame(data)\n",
    "    # Add 'Label' column\n",
    "    df_train['Label'] = labels\n",
    "\n",
    "    # TEST \n",
    "    # Set the maximum number of iterations per subfolder\n",
    "    max_iterations_per_subfolder = 5\n",
    "\n",
    "    data_test_dir = os.path.join(data_dir, 'test')\n",
    "    counter = 0  # Initialize counter\n",
    "\n",
    "    for label, subfolder in enumerate(subfolders):\n",
    "        folder_path = os.path.join(data_test_dir, subfolder)\n",
    "        image_files = os.listdir(folder_path)\n",
    "        \n",
    "        # Reset the counter for each subfolder\n",
    "        counter_per_subfolder = 0  \n",
    "        \n",
    "        for image_file in image_files:\n",
    "            # Check if the maximum number of iterations per subfolder has been reached\n",
    "            if counter_per_subfolder >= max_iterations_per_subfolder:\n",
    "                break  # Exit the loop for the current subfolder\n",
    "\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            try:\n",
    "                image_info = extract_features(image_path)\n",
    "                # Add image info and label to lists\n",
    "                data_.append(image_info)\n",
    "                labels_.append(label)\n",
    "                counter += 1  # Increment the total counter\n",
    "                counter_per_subfolder += 1  # Increment the counter for the current subfolder\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df_test = pd.DataFrame(data_)\n",
    "    # Add 'Label' column\n",
    "    df_test['Label'] = labels_\n",
    "    df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_testing:\n",
    "    data_train_dir = os.path.join(data_dir, 'train')\n",
    "    for label, subfolder in enumerate(subfolders):\n",
    "        folder_path = os.path.join(data_train_dir, subfolder)\n",
    "        image_files = os.listdir(folder_path)\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            try:\n",
    "                image_info = extract_features(image_path)\n",
    "                # Add image info and label to lists\n",
    "                data.append(image_info)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "    # Create a DataFrame\n",
    "    df_train = pd.DataFrame(data)\n",
    "    # Add 'Label' column\n",
    "    df_train['Label'] = labels\n",
    "    df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_testing:\n",
    "    data_test_dir = os.path.join(data_dir, 'test')\n",
    "    for label, subfolder in enumerate(subfolders):\n",
    "        folder_path = os.path.join(data_test_dir, subfolder)\n",
    "        image_files = os.listdir(folder_path)\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            try:\n",
    "                image_info = extract_features(image_path)\n",
    "                # Add image info and label to lists\n",
    "                data_.append(image_info)\n",
    "                labels_.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "    # Create a DataFrame\n",
    "    df_test = pd.DataFrame(data_)\n",
    "    # Add 'Label' column\n",
    "    df_test['Label'] = labels_\n",
    "    df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataframes into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./data/train_data.csv', index=False)\n",
    "df_test.to_csv('./data/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove columns with high and low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Average_Red</th>\n",
       "      <th>Average_Green</th>\n",
       "      <th>Average_Blue</th>\n",
       "      <th>ResNet_Feature_0</th>\n",
       "      <th>ResNet_Feature_1</th>\n",
       "      <th>ResNet_Feature_3</th>\n",
       "      <th>ResNet_Feature_4</th>\n",
       "      <th>ResNet_Feature_5</th>\n",
       "      <th>ResNet_Feature_6</th>\n",
       "      <th>...</th>\n",
       "      <th>ResNet_Feature_2035</th>\n",
       "      <th>ResNet_Feature_2037</th>\n",
       "      <th>ResNet_Feature_2038</th>\n",
       "      <th>ResNet_Feature_2042</th>\n",
       "      <th>ResNet_Feature_2043</th>\n",
       "      <th>ResNet_Feature_2044</th>\n",
       "      <th>ResNet_Feature_2045</th>\n",
       "      <th>ResNet_Feature_2046</th>\n",
       "      <th>ResNet_Feature_2047</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>112.418660</td>\n",
       "      <td>108.282672</td>\n",
       "      <td>87.389278</td>\n",
       "      <td>0.528285</td>\n",
       "      <td>0.029902</td>\n",
       "      <td>1.315238</td>\n",
       "      <td>0.634177</td>\n",
       "      <td>0.193334</td>\n",
       "      <td>0.283515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.855130</td>\n",
       "      <td>0.054288</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.028109</td>\n",
       "      <td>0.123447</td>\n",
       "      <td>1.839331</td>\n",
       "      <td>0.870836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>57.509216</td>\n",
       "      <td>49.321968</td>\n",
       "      <td>47.493701</td>\n",
       "      <td>1.309414</td>\n",
       "      <td>1.736403</td>\n",
       "      <td>0.170851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.932875</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566767</td>\n",
       "      <td>0.067213</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.074207</td>\n",
       "      <td>0.539539</td>\n",
       "      <td>0.147099</td>\n",
       "      <td>0.291170</td>\n",
       "      <td>0.246790</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>96.605145</td>\n",
       "      <td>92.911129</td>\n",
       "      <td>85.275176</td>\n",
       "      <td>0.559744</td>\n",
       "      <td>0.069923</td>\n",
       "      <td>1.542000</td>\n",
       "      <td>0.559682</td>\n",
       "      <td>0.485890</td>\n",
       "      <td>0.168751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738310</td>\n",
       "      <td>0.549561</td>\n",
       "      <td>0.338623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.304345</td>\n",
       "      <td>0.307587</td>\n",
       "      <td>0.581977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>84.832106</td>\n",
       "      <td>81.504769</td>\n",
       "      <td>82.176915</td>\n",
       "      <td>0.150879</td>\n",
       "      <td>0.339460</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>1.609796</td>\n",
       "      <td>0.126857</td>\n",
       "      <td>0.307259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.804228</td>\n",
       "      <td>1.851759</td>\n",
       "      <td>0.153898</td>\n",
       "      <td>0.478254</td>\n",
       "      <td>0.911931</td>\n",
       "      <td>1.486619</td>\n",
       "      <td>1.318023</td>\n",
       "      <td>0.614202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>72.107272</td>\n",
       "      <td>64.458826</td>\n",
       "      <td>47.950459</td>\n",
       "      <td>0.592783</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>0.032991</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.026858</td>\n",
       "      <td>2.837760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653814</td>\n",
       "      <td>1.729966</td>\n",
       "      <td>0.078469</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.060701</td>\n",
       "      <td>0.745618</td>\n",
       "      <td>0.513924</td>\n",
       "      <td>0.269124</td>\n",
       "      <td>2.430139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>86.809985</td>\n",
       "      <td>73.588483</td>\n",
       "      <td>70.433480</td>\n",
       "      <td>0.027479</td>\n",
       "      <td>0.565555</td>\n",
       "      <td>0.454398</td>\n",
       "      <td>0.109362</td>\n",
       "      <td>0.334267</td>\n",
       "      <td>0.217785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>1.740194</td>\n",
       "      <td>0.147026</td>\n",
       "      <td>0.104712</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>1.185171</td>\n",
       "      <td>0.618679</td>\n",
       "      <td>0.028477</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>102.087517</td>\n",
       "      <td>88.566867</td>\n",
       "      <td>85.885807</td>\n",
       "      <td>0.569003</td>\n",
       "      <td>0.801708</td>\n",
       "      <td>2.996027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.016686</td>\n",
       "      <td>0.308584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064533</td>\n",
       "      <td>1.298695</td>\n",
       "      <td>1.040156</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.278814</td>\n",
       "      <td>0.192668</td>\n",
       "      <td>3.525775</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0.326274</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>60.445131</td>\n",
       "      <td>61.805913</td>\n",
       "      <td>59.170038</td>\n",
       "      <td>1.818681</td>\n",
       "      <td>0.569909</td>\n",
       "      <td>1.983910</td>\n",
       "      <td>0.036266</td>\n",
       "      <td>0.658086</td>\n",
       "      <td>0.299647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427472</td>\n",
       "      <td>1.030174</td>\n",
       "      <td>1.582558</td>\n",
       "      <td>0.133654</td>\n",
       "      <td>0.436760</td>\n",
       "      <td>0.298897</td>\n",
       "      <td>0.877941</td>\n",
       "      <td>0.526452</td>\n",
       "      <td>1.503341</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>90.063471</td>\n",
       "      <td>57.759946</td>\n",
       "      <td>58.699454</td>\n",
       "      <td>1.452093</td>\n",
       "      <td>0.485698</td>\n",
       "      <td>1.711687</td>\n",
       "      <td>0.077760</td>\n",
       "      <td>0.254750</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>2.981479</td>\n",
       "      <td>1.193068</td>\n",
       "      <td>0.151251</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.230602</td>\n",
       "      <td>0.352457</td>\n",
       "      <td>0.597941</td>\n",
       "      <td>0.900871</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>37.754594</td>\n",
       "      <td>54.597526</td>\n",
       "      <td>30.803262</td>\n",
       "      <td>1.121474</td>\n",
       "      <td>0.548379</td>\n",
       "      <td>1.620736</td>\n",
       "      <td>0.456956</td>\n",
       "      <td>0.180460</td>\n",
       "      <td>0.305402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151267</td>\n",
       "      <td>0.261816</td>\n",
       "      <td>0.180977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226959</td>\n",
       "      <td>1.145608</td>\n",
       "      <td>0.445406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4442 rows × 1625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Image_Path  Average_Red  \\\n",
       "0     ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   112.418660   \n",
       "1     ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    57.509216   \n",
       "2     ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    96.605145   \n",
       "3     ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    84.832106   \n",
       "4     ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    72.107272   \n",
       "...                                                 ...          ...   \n",
       "4437  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    86.809985   \n",
       "4438  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   102.087517   \n",
       "4439  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    60.445131   \n",
       "4440  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    90.063471   \n",
       "4441  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...    37.754594   \n",
       "\n",
       "      Average_Green  Average_Blue  ResNet_Feature_0  ResNet_Feature_1  \\\n",
       "0        108.282672     87.389278          0.528285          0.029902   \n",
       "1         49.321968     47.493701          1.309414          1.736403   \n",
       "2         92.911129     85.275176          0.559744          0.069923   \n",
       "3         81.504769     82.176915          0.150879          0.339460   \n",
       "4         64.458826     47.950459          0.592783          0.034610   \n",
       "...             ...           ...               ...               ...   \n",
       "4437      73.588483     70.433480          0.027479          0.565555   \n",
       "4438      88.566867     85.885807          0.569003          0.801708   \n",
       "4439      61.805913     59.170038          1.818681          0.569909   \n",
       "4440      57.759946     58.699454          1.452093          0.485698   \n",
       "4441      54.597526     30.803262          1.121474          0.548379   \n",
       "\n",
       "      ResNet_Feature_3  ResNet_Feature_4  ResNet_Feature_5  ResNet_Feature_6  \\\n",
       "0             1.315238          0.634177          0.193334          0.283515   \n",
       "1             0.170851          0.000000          2.932875          0.530004   \n",
       "2             1.542000          0.559682          0.485890          0.168751   \n",
       "3             0.028849          1.609796          0.126857          0.307259   \n",
       "4             0.032991          0.019603          0.026858          2.837760   \n",
       "...                ...               ...               ...               ...   \n",
       "4437          0.454398          0.109362          0.334267          0.217785   \n",
       "4438          2.996027          0.000000          1.016686          0.308584   \n",
       "4439          1.983910          0.036266          0.658086          0.299647   \n",
       "4440          1.711687          0.077760          0.254750          0.015883   \n",
       "4441          1.620736          0.456956          0.180460          0.305402   \n",
       "\n",
       "      ...  ResNet_Feature_2035  ResNet_Feature_2037  ResNet_Feature_2038  \\\n",
       "0     ...             0.238022             0.855130             0.054288   \n",
       "1     ...             0.566767             0.067213             0.082491   \n",
       "2     ...             0.738310             0.549561             0.338623   \n",
       "3     ...             0.000000             1.804228             1.851759   \n",
       "4     ...             0.653814             1.729966             0.078469   \n",
       "...   ...                  ...                  ...                  ...   \n",
       "4437  ...             0.081116             1.740194             0.147026   \n",
       "4438  ...             0.064533             1.298695             1.040156   \n",
       "4439  ...             0.427472             1.030174             1.582558   \n",
       "4440  ...             0.013486             2.981479             1.193068   \n",
       "4441  ...             0.151267             0.261816             0.180977   \n",
       "\n",
       "      ResNet_Feature_2042  ResNet_Feature_2043  ResNet_Feature_2044  \\\n",
       "0                0.005966             0.028109             0.123447   \n",
       "1                0.074207             0.539539             0.147099   \n",
       "2                0.000000             0.034666             0.000000   \n",
       "3                0.153898             0.478254             0.911931   \n",
       "4                0.009067             0.060701             0.745618   \n",
       "...                   ...                  ...                  ...   \n",
       "4437             0.104712             0.004578             0.253000   \n",
       "4438             0.107155             0.278814             0.192668   \n",
       "4439             0.133654             0.436760             0.298897   \n",
       "4440             0.151251             0.190500             0.230602   \n",
       "4441             0.000000             0.000000             0.226959   \n",
       "\n",
       "      ResNet_Feature_2045  ResNet_Feature_2046  ResNet_Feature_2047  Label  \n",
       "0                1.839331             0.870836             0.000000      0  \n",
       "1                0.291170             0.246790             0.003313      0  \n",
       "2                3.304345             0.307587             0.581977      0  \n",
       "3                1.486619             1.318023             0.614202      0  \n",
       "4                0.513924             0.269124             2.430139      0  \n",
       "...                   ...                  ...                  ...    ...  \n",
       "4437             1.185171             0.618679             0.028477      3  \n",
       "4438             3.525775             0.019981             0.326274      3  \n",
       "4439             0.877941             0.526452             1.503341      3  \n",
       "4440             0.352457             0.597941             0.900871      3  \n",
       "4441             1.145608             0.445406             0.000000      3  \n",
       "\n",
       "[4442 rows x 1625 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "# Separate features and labels from training and testing dataframes\n",
    "X_train = df_train.drop(columns=['Image_Path', 'Label'])\n",
    "y_train = df_train['Label']\n",
    "X_test = df_test.drop(columns=['Image_Path', 'Label'])\n",
    "y_test = df_test['Label']\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(X_train)\n",
    "\n",
    "# Get mask of features to keep\n",
    "mask = selector.get_support()\n",
    "\n",
    "# Filter the original dataframes based on the mask\n",
    "selected_features_train = X_train.columns[mask]\n",
    "selected_features_test = X_test.columns[mask]\n",
    "\n",
    "df_train_filtered = df_train[['Image_Path', *selected_features_train, 'Label']]\n",
    "df_test_filtered = df_test[['Image_Path', *selected_features_test, 'Label']]\n",
    "\n",
    "# Display or return the filtered dataframes\n",
    "df_train_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average_Red</th>\n",
       "      <th>Average_Green</th>\n",
       "      <th>Average_Blue</th>\n",
       "      <th>ResNet_Feature_0</th>\n",
       "      <th>ResNet_Feature_1</th>\n",
       "      <th>ResNet_Feature_3</th>\n",
       "      <th>ResNet_Feature_4</th>\n",
       "      <th>ResNet_Feature_5</th>\n",
       "      <th>ResNet_Feature_6</th>\n",
       "      <th>ResNet_Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>ResNet_Feature_2037</th>\n",
       "      <th>ResNet_Feature_2038</th>\n",
       "      <th>ResNet_Feature_2042</th>\n",
       "      <th>ResNet_Feature_2043</th>\n",
       "      <th>ResNet_Feature_2044</th>\n",
       "      <th>ResNet_Feature_2045</th>\n",
       "      <th>ResNet_Feature_2046</th>\n",
       "      <th>ResNet_Feature_2047</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848213</td>\n",
       "      <td>0.681923</td>\n",
       "      <td>0.327124</td>\n",
       "      <td>-0.659603</td>\n",
       "      <td>-1.055975</td>\n",
       "      <td>0.069466</td>\n",
       "      <td>0.727703</td>\n",
       "      <td>-0.707818</td>\n",
       "      <td>-0.208360</td>\n",
       "      <td>-0.395763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485969</td>\n",
       "      <td>-0.851324</td>\n",
       "      <td>-0.713420</td>\n",
       "      <td>-0.830392</td>\n",
       "      <td>-0.654132</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.202505</td>\n",
       "      <td>-0.878941</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.109578</td>\n",
       "      <td>-1.659803</td>\n",
       "      <td>-1.106252</td>\n",
       "      <td>0.480751</td>\n",
       "      <td>1.396950</td>\n",
       "      <td>-1.125619</td>\n",
       "      <td>-0.873168</td>\n",
       "      <td>3.887186</td>\n",
       "      <td>0.320502</td>\n",
       "      <td>-0.678415</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.459662</td>\n",
       "      <td>-0.818310</td>\n",
       "      <td>-0.516428</td>\n",
       "      <td>0.500140</td>\n",
       "      <td>-0.607831</td>\n",
       "      <td>-1.117210</td>\n",
       "      <td>-0.721775</td>\n",
       "      <td>-0.870777</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.284384</td>\n",
       "      <td>0.071416</td>\n",
       "      <td>0.251168</td>\n",
       "      <td>-0.613677</td>\n",
       "      <td>-0.998449</td>\n",
       "      <td>0.306273</td>\n",
       "      <td>0.539652</td>\n",
       "      <td>-0.217116</td>\n",
       "      <td>-0.454596</td>\n",
       "      <td>-0.190816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.863586</td>\n",
       "      <td>-0.518479</td>\n",
       "      <td>-0.730641</td>\n",
       "      <td>-0.813334</td>\n",
       "      <td>-0.895791</td>\n",
       "      <td>1.177846</td>\n",
       "      <td>-0.631729</td>\n",
       "      <td>0.555288</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.135383</td>\n",
       "      <td>-0.381608</td>\n",
       "      <td>0.139853</td>\n",
       "      <td>-1.210569</td>\n",
       "      <td>-0.611016</td>\n",
       "      <td>-1.273911</td>\n",
       "      <td>3.190484</td>\n",
       "      <td>-0.819320</td>\n",
       "      <td>-0.157415</td>\n",
       "      <td>-0.395344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686910</td>\n",
       "      <td>1.252812</td>\n",
       "      <td>-0.286386</td>\n",
       "      <td>0.340702</td>\n",
       "      <td>0.889402</td>\n",
       "      <td>-0.206668</td>\n",
       "      <td>0.864838</td>\n",
       "      <td>0.634703</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.589086</td>\n",
       "      <td>-1.058617</td>\n",
       "      <td>-1.089842</td>\n",
       "      <td>-0.565444</td>\n",
       "      <td>-1.049207</td>\n",
       "      <td>-1.269586</td>\n",
       "      <td>-0.823683</td>\n",
       "      <td>-0.987047</td>\n",
       "      <td>5.271980</td>\n",
       "      <td>-0.847768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595139</td>\n",
       "      <td>-0.823017</td>\n",
       "      <td>-0.704468</td>\n",
       "      <td>-0.745602</td>\n",
       "      <td>0.563827</td>\n",
       "      <td>-0.947544</td>\n",
       "      <td>-0.688697</td>\n",
       "      <td>5.109914</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>-0.064862</td>\n",
       "      <td>-0.696017</td>\n",
       "      <td>-0.282067</td>\n",
       "      <td>-1.390717</td>\n",
       "      <td>-0.286028</td>\n",
       "      <td>-0.829510</td>\n",
       "      <td>-0.597103</td>\n",
       "      <td>-0.471432</td>\n",
       "      <td>-0.349388</td>\n",
       "      <td>-0.453290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607778</td>\n",
       "      <td>-0.742764</td>\n",
       "      <td>-0.428369</td>\n",
       "      <td>-0.891611</td>\n",
       "      <td>-0.400520</td>\n",
       "      <td>-0.436273</td>\n",
       "      <td>-0.170968</td>\n",
       "      <td>-0.808760</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>0.479857</td>\n",
       "      <td>-0.101124</td>\n",
       "      <td>0.273107</td>\n",
       "      <td>-0.600159</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>1.824714</td>\n",
       "      <td>-0.873168</td>\n",
       "      <td>0.673182</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.575913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062181</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>-0.421318</td>\n",
       "      <td>-0.178159</td>\n",
       "      <td>-0.518624</td>\n",
       "      <td>1.346503</td>\n",
       "      <td>-1.057704</td>\n",
       "      <td>-0.074869</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>-1.004898</td>\n",
       "      <td>-1.163982</td>\n",
       "      <td>-0.686743</td>\n",
       "      <td>1.224218</td>\n",
       "      <td>-0.279770</td>\n",
       "      <td>0.767760</td>\n",
       "      <td>-0.781620</td>\n",
       "      <td>0.071707</td>\n",
       "      <td>-0.173747</td>\n",
       "      <td>0.196583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269653</td>\n",
       "      <td>0.937683</td>\n",
       "      <td>-0.344822</td>\n",
       "      <td>0.232750</td>\n",
       "      <td>-0.310672</td>\n",
       "      <td>-0.670282</td>\n",
       "      <td>-0.307566</td>\n",
       "      <td>2.825905</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>0.051141</td>\n",
       "      <td>-1.324674</td>\n",
       "      <td>-0.703650</td>\n",
       "      <td>0.689045</td>\n",
       "      <td>-0.400815</td>\n",
       "      <td>0.483477</td>\n",
       "      <td>-0.676877</td>\n",
       "      <td>-0.604806</td>\n",
       "      <td>-0.782585</td>\n",
       "      <td>0.840684</td>\n",
       "      <td>...</td>\n",
       "      <td>2.141737</td>\n",
       "      <td>0.481742</td>\n",
       "      <td>-0.294026</td>\n",
       "      <td>-0.407916</td>\n",
       "      <td>-0.444365</td>\n",
       "      <td>-1.070529</td>\n",
       "      <td>-0.201682</td>\n",
       "      <td>1.341173</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>-1.813928</td>\n",
       "      <td>-1.450275</td>\n",
       "      <td>-1.705910</td>\n",
       "      <td>0.206381</td>\n",
       "      <td>-0.310716</td>\n",
       "      <td>0.388497</td>\n",
       "      <td>0.280340</td>\n",
       "      <td>-0.729411</td>\n",
       "      <td>-0.161400</td>\n",
       "      <td>-0.888185</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.219176</td>\n",
       "      <td>-0.703021</td>\n",
       "      <td>-0.730641</td>\n",
       "      <td>-0.903520</td>\n",
       "      <td>-0.451496</td>\n",
       "      <td>-0.466407</td>\n",
       "      <td>-0.427604</td>\n",
       "      <td>-0.878941</td>\n",
       "      <td>./kaggle/input/tom_and_jerry/tom_and_jerry/tra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4442 rows × 1625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Average_Red  Average_Green  Average_Blue  ResNet_Feature_0  \\\n",
       "0        0.848213       0.681923      0.327124         -0.659603   \n",
       "1       -1.109578      -1.659803     -1.106252          0.480751   \n",
       "2        0.284384       0.071416      0.251168         -0.613677   \n",
       "3       -0.135383      -0.381608      0.139853         -1.210569   \n",
       "4       -0.589086      -1.058617     -1.089842         -0.565444   \n",
       "...           ...            ...           ...               ...   \n",
       "4437    -0.064862      -0.696017     -0.282067         -1.390717   \n",
       "4438     0.479857      -0.101124      0.273107         -0.600159   \n",
       "4439    -1.004898      -1.163982     -0.686743          1.224218   \n",
       "4440     0.051141      -1.324674     -0.703650          0.689045   \n",
       "4441    -1.813928      -1.450275     -1.705910          0.206381   \n",
       "\n",
       "      ResNet_Feature_1  ResNet_Feature_3  ResNet_Feature_4  ResNet_Feature_5  \\\n",
       "0            -1.055975          0.069466          0.727703         -0.707818   \n",
       "1             1.396950         -1.125619         -0.873168          3.887186   \n",
       "2            -0.998449          0.306273          0.539652         -0.217116   \n",
       "3            -0.611016         -1.273911          3.190484         -0.819320   \n",
       "4            -1.049207         -1.269586         -0.823683         -0.987047   \n",
       "...                ...               ...               ...               ...   \n",
       "4437         -0.286028         -0.829510         -0.597103         -0.471432   \n",
       "4438          0.053419          1.824714         -0.873168          0.673182   \n",
       "4439         -0.279770          0.767760         -0.781620          0.071707   \n",
       "4440         -0.400815          0.483477         -0.676877         -0.604806   \n",
       "4441         -0.310716          0.388497          0.280340         -0.729411   \n",
       "\n",
       "      ResNet_Feature_6  ResNet_Feature_8  ...  ResNet_Feature_2037  \\\n",
       "0            -0.208360         -0.395763  ...            -0.485969   \n",
       "1             0.320502         -0.678415  ...            -1.459662   \n",
       "2            -0.454596         -0.190816  ...            -0.863586   \n",
       "3            -0.157415         -0.395344  ...             0.686910   \n",
       "4             5.271980         -0.847768  ...             0.595139   \n",
       "...                ...               ...  ...                  ...   \n",
       "4437         -0.349388         -0.453290  ...             0.607778   \n",
       "4438         -0.154571          0.575913  ...             0.062181   \n",
       "4439         -0.173747          0.196583  ...            -0.269653   \n",
       "4440         -0.782585          0.840684  ...             2.141737   \n",
       "4441         -0.161400         -0.888185  ...            -1.219176   \n",
       "\n",
       "      ResNet_Feature_2038  ResNet_Feature_2042  ResNet_Feature_2043  \\\n",
       "0               -0.851324            -0.713420            -0.830392   \n",
       "1               -0.818310            -0.516428             0.500140   \n",
       "2               -0.518479            -0.730641            -0.813334   \n",
       "3                1.252812            -0.286386             0.340702   \n",
       "4               -0.823017            -0.704468            -0.745602   \n",
       "...                   ...                  ...                  ...   \n",
       "4437            -0.742764            -0.428369            -0.891611   \n",
       "4438             0.302742            -0.421318            -0.178159   \n",
       "4439             0.937683            -0.344822             0.232750   \n",
       "4440             0.481742            -0.294026            -0.407916   \n",
       "4441            -0.703021            -0.730641            -0.903520   \n",
       "\n",
       "      ResNet_Feature_2044  ResNet_Feature_2045  ResNet_Feature_2046  \\\n",
       "0               -0.654132             0.061983             0.202505   \n",
       "1               -0.607831            -1.117210            -0.721775   \n",
       "2               -0.895791             1.177846            -0.631729   \n",
       "3                0.889402            -0.206668             0.864838   \n",
       "4                0.563827            -0.947544            -0.688697   \n",
       "...                   ...                  ...                  ...   \n",
       "4437            -0.400520            -0.436273            -0.170968   \n",
       "4438            -0.518624             1.346503            -1.057704   \n",
       "4439            -0.310672            -0.670282            -0.307566   \n",
       "4440            -0.444365            -1.070529            -0.201682   \n",
       "4441            -0.451496            -0.466407            -0.427604   \n",
       "\n",
       "      ResNet_Feature_2047                                         Image_Path  \\\n",
       "0               -0.878941  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "1               -0.870777  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "2                0.555288  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "3                0.634703  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "4                5.109914  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "...                   ...                                                ...   \n",
       "4437            -0.808760  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "4438            -0.074869  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "4439             2.825905  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "4440             1.341173  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "4441            -0.878941  ./kaggle/input/tom_and_jerry/tom_and_jerry/tra...   \n",
       "\n",
       "      Label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "4437      3  \n",
       "4438      3  \n",
       "4439      3  \n",
       "4440      3  \n",
       "4441      3  \n",
       "\n",
       "[4442 rows x 1625 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_train = df_train_filtered.drop(columns=['Image_Path', 'Label'])\n",
    "y_train = df_train_filtered['Label']\n",
    "X_test = df_test_filtered.drop(columns=['Image_Path', 'Label'])\n",
    "y_test = df_test_filtered['Label']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test features using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create new DataFrames with the scaled features\n",
    "df_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "df_train_scaled['Image_Path'] = df_train_filtered['Image_Path']\n",
    "df_train_scaled['Label'] = y_train\n",
    "\n",
    "df_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "df_test_scaled['Image_Path'] = df_test_filtered['Image_Path']\n",
    "df_test_scaled['Label'] = y_test\n",
    "\n",
    "df_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4442 entries, 0 to 4441\n",
      "Columns: 1625 entries, Average_Red to Label\n",
      "dtypes: float64(1623), int64(1), object(1)\n",
      "memory usage: 55.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average_Red</th>\n",
       "      <th>Average_Green</th>\n",
       "      <th>Average_Blue</th>\n",
       "      <th>ResNet_Feature_0</th>\n",
       "      <th>ResNet_Feature_1</th>\n",
       "      <th>ResNet_Feature_3</th>\n",
       "      <th>ResNet_Feature_4</th>\n",
       "      <th>ResNet_Feature_5</th>\n",
       "      <th>ResNet_Feature_6</th>\n",
       "      <th>ResNet_Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>ResNet_Feature_2035</th>\n",
       "      <th>ResNet_Feature_2037</th>\n",
       "      <th>ResNet_Feature_2038</th>\n",
       "      <th>ResNet_Feature_2042</th>\n",
       "      <th>ResNet_Feature_2043</th>\n",
       "      <th>ResNet_Feature_2044</th>\n",
       "      <th>ResNet_Feature_2045</th>\n",
       "      <th>ResNet_Feature_2046</th>\n",
       "      <th>ResNet_Feature_2047</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4.442000e+03</td>\n",
       "      <td>4442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.277685e-17</td>\n",
       "      <td>-5.758563e-17</td>\n",
       "      <td>3.327170e-16</td>\n",
       "      <td>-1.343665e-16</td>\n",
       "      <td>3.199202e-17</td>\n",
       "      <td>4.478883e-17</td>\n",
       "      <td>2.559361e-17</td>\n",
       "      <td>-1.759561e-16</td>\n",
       "      <td>-1.023745e-16</td>\n",
       "      <td>3.839042e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.317925e-17</td>\n",
       "      <td>-2.495377e-16</td>\n",
       "      <td>5.118723e-17</td>\n",
       "      <td>-2.879282e-17</td>\n",
       "      <td>-1.307674e-16</td>\n",
       "      <td>-6.398404e-18</td>\n",
       "      <td>-3.199202e-18</td>\n",
       "      <td>3.519122e-17</td>\n",
       "      <td>4.478883e-17</td>\n",
       "      <td>1.339487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>1.000113e+00</td>\n",
       "      <td>0.982629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.160064e+00</td>\n",
       "      <td>-3.618710e+00</td>\n",
       "      <td>-2.812616e+00</td>\n",
       "      <td>-1.430834e+00</td>\n",
       "      <td>-1.098956e+00</td>\n",
       "      <td>-1.304039e+00</td>\n",
       "      <td>-8.731679e-01</td>\n",
       "      <td>-1.032095e+00</td>\n",
       "      <td>-8.166636e-01</td>\n",
       "      <td>-1.085518e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.586243e-01</td>\n",
       "      <td>-1.498629e+00</td>\n",
       "      <td>-9.148739e-01</td>\n",
       "      <td>-7.306406e-01</td>\n",
       "      <td>-9.035198e-01</td>\n",
       "      <td>-8.957910e-01</td>\n",
       "      <td>-1.338986e+00</td>\n",
       "      <td>-1.087299e+00</td>\n",
       "      <td>-8.789406e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.722023e-01</td>\n",
       "      <td>-7.003434e-01</td>\n",
       "      <td>-6.910825e-01</td>\n",
       "      <td>-7.552315e-01</td>\n",
       "      <td>-7.811819e-01</td>\n",
       "      <td>-7.350863e-01</td>\n",
       "      <td>-6.940056e-01</td>\n",
       "      <td>-7.683707e-01</td>\n",
       "      <td>-6.644761e-01</td>\n",
       "      <td>-7.441747e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.200889e-01</td>\n",
       "      <td>-7.113667e-01</td>\n",
       "      <td>-7.122688e-01</td>\n",
       "      <td>-6.458116e-01</td>\n",
       "      <td>-7.335242e-01</td>\n",
       "      <td>-6.563946e-01</td>\n",
       "      <td>-7.954865e-01</td>\n",
       "      <td>-7.262885e-01</td>\n",
       "      <td>-7.013023e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.903606e-02</td>\n",
       "      <td>-1.180393e-02</td>\n",
       "      <td>4.654658e-02</td>\n",
       "      <td>-2.177038e-01</td>\n",
       "      <td>-2.707356e-01</td>\n",
       "      <td>-2.019221e-01</td>\n",
       "      <td>-3.323213e-01</td>\n",
       "      <td>-2.881285e-01</td>\n",
       "      <td>-3.252937e-01</td>\n",
       "      <td>-2.743256e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.796353e-01</td>\n",
       "      <td>-2.247654e-01</td>\n",
       "      <td>-3.354450e-01</td>\n",
       "      <td>-3.662074e-01</td>\n",
       "      <td>-3.119341e-01</td>\n",
       "      <td>-2.892899e-01</td>\n",
       "      <td>-2.297756e-01</td>\n",
       "      <td>-2.812915e-01</td>\n",
       "      <td>-3.192609e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.483564e-01</td>\n",
       "      <td>7.099374e-01</td>\n",
       "      <td>7.047485e-01</td>\n",
       "      <td>5.132925e-01</td>\n",
       "      <td>5.010007e-01</td>\n",
       "      <td>4.728043e-01</td>\n",
       "      <td>3.170165e-01</td>\n",
       "      <td>4.841471e-01</td>\n",
       "      <td>2.704883e-01</td>\n",
       "      <td>4.326473e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143923e-01</td>\n",
       "      <td>4.376777e-01</td>\n",
       "      <td>3.627064e-01</td>\n",
       "      <td>2.736847e-01</td>\n",
       "      <td>3.825548e-01</td>\n",
       "      <td>3.492450e-01</td>\n",
       "      <td>5.777017e-01</td>\n",
       "      <td>3.984208e-01</td>\n",
       "      <td>3.724615e-01</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.146270e+00</td>\n",
       "      <td>3.738403e+00</td>\n",
       "      <td>3.532498e+00</td>\n",
       "      <td>4.532798e+00</td>\n",
       "      <td>5.198140e+00</td>\n",
       "      <td>7.419892e+00</td>\n",
       "      <td>6.841592e+00</td>\n",
       "      <td>7.205941e+00</td>\n",
       "      <td>8.683028e+00</td>\n",
       "      <td>5.451306e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128758e+01</td>\n",
       "      <td>5.156668e+00</td>\n",
       "      <td>7.222169e+00</td>\n",
       "      <td>1.540062e+01</td>\n",
       "      <td>1.015676e+01</td>\n",
       "      <td>1.101993e+01</td>\n",
       "      <td>5.502604e+00</td>\n",
       "      <td>6.735501e+00</td>\n",
       "      <td>9.118559e+00</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Average_Red  Average_Green  Average_Blue  ResNet_Feature_0  \\\n",
       "count  4.442000e+03   4.442000e+03  4.442000e+03      4.442000e+03   \n",
       "mean   9.277685e-17  -5.758563e-17  3.327170e-16     -1.343665e-16   \n",
       "std    1.000113e+00   1.000113e+00  1.000113e+00      1.000113e+00   \n",
       "min   -3.160064e+00  -3.618710e+00 -2.812616e+00     -1.430834e+00   \n",
       "25%   -6.722023e-01  -7.003434e-01 -6.910825e-01     -7.552315e-01   \n",
       "50%    5.903606e-02  -1.180393e-02  4.654658e-02     -2.177038e-01   \n",
       "75%    6.483564e-01   7.099374e-01  7.047485e-01      5.132925e-01   \n",
       "max    4.146270e+00   3.738403e+00  3.532498e+00      4.532798e+00   \n",
       "\n",
       "       ResNet_Feature_1  ResNet_Feature_3  ResNet_Feature_4  ResNet_Feature_5  \\\n",
       "count      4.442000e+03      4.442000e+03      4.442000e+03      4.442000e+03   \n",
       "mean       3.199202e-17      4.478883e-17      2.559361e-17     -1.759561e-16   \n",
       "std        1.000113e+00      1.000113e+00      1.000113e+00      1.000113e+00   \n",
       "min       -1.098956e+00     -1.304039e+00     -8.731679e-01     -1.032095e+00   \n",
       "25%       -7.811819e-01     -7.350863e-01     -6.940056e-01     -7.683707e-01   \n",
       "50%       -2.707356e-01     -2.019221e-01     -3.323213e-01     -2.881285e-01   \n",
       "75%        5.010007e-01      4.728043e-01      3.170165e-01      4.841471e-01   \n",
       "max        5.198140e+00      7.419892e+00      6.841592e+00      7.205941e+00   \n",
       "\n",
       "       ResNet_Feature_6  ResNet_Feature_8  ...  ResNet_Feature_2035  \\\n",
       "count      4.442000e+03      4.442000e+03  ...         4.442000e+03   \n",
       "mean      -1.023745e-16      3.839042e-17  ...        -8.317925e-17   \n",
       "std        1.000113e+00      1.000113e+00  ...         1.000113e+00   \n",
       "min       -8.166636e-01     -1.085518e+00  ...        -6.586243e-01   \n",
       "25%       -6.644761e-01     -7.441747e-01  ...        -6.200889e-01   \n",
       "50%       -3.252937e-01     -2.743256e-01  ...        -3.796353e-01   \n",
       "75%        2.704883e-01      4.326473e-01  ...         2.143923e-01   \n",
       "max        8.683028e+00      5.451306e+00  ...         1.128758e+01   \n",
       "\n",
       "       ResNet_Feature_2037  ResNet_Feature_2038  ResNet_Feature_2042  \\\n",
       "count         4.442000e+03         4.442000e+03         4.442000e+03   \n",
       "mean         -2.495377e-16         5.118723e-17        -2.879282e-17   \n",
       "std           1.000113e+00         1.000113e+00         1.000113e+00   \n",
       "min          -1.498629e+00        -9.148739e-01        -7.306406e-01   \n",
       "25%          -7.113667e-01        -7.122688e-01        -6.458116e-01   \n",
       "50%          -2.247654e-01        -3.354450e-01        -3.662074e-01   \n",
       "75%           4.376777e-01         3.627064e-01         2.736847e-01   \n",
       "max           5.156668e+00         7.222169e+00         1.540062e+01   \n",
       "\n",
       "       ResNet_Feature_2043  ResNet_Feature_2044  ResNet_Feature_2045  \\\n",
       "count         4.442000e+03         4.442000e+03         4.442000e+03   \n",
       "mean         -1.307674e-16        -6.398404e-18        -3.199202e-18   \n",
       "std           1.000113e+00         1.000113e+00         1.000113e+00   \n",
       "min          -9.035198e-01        -8.957910e-01        -1.338986e+00   \n",
       "25%          -7.335242e-01        -6.563946e-01        -7.954865e-01   \n",
       "50%          -3.119341e-01        -2.892899e-01        -2.297756e-01   \n",
       "75%           3.825548e-01         3.492450e-01         5.777017e-01   \n",
       "max           1.015676e+01         1.101993e+01         5.502604e+00   \n",
       "\n",
       "       ResNet_Feature_2046  ResNet_Feature_2047        Label  \n",
       "count         4.442000e+03         4.442000e+03  4442.000000  \n",
       "mean          3.519122e-17         4.478883e-17     1.339487  \n",
       "std           1.000113e+00         1.000113e+00     0.982629  \n",
       "min          -1.087299e+00        -8.789406e-01     0.000000  \n",
       "25%          -7.262885e-01        -7.013023e-01     1.000000  \n",
       "50%          -2.812915e-01        -3.192609e-01     1.000000  \n",
       "75%           3.984208e-01         3.724615e-01     2.000000  \n",
       "max           6.735501e+00         9.118559e+00     3.000000  \n",
       "\n",
       "[8 rows x 1624 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of label column\n",
    "plt.figure(figsize=(8, 6))\n",
    "df_train_scaled['Label'].map(label_categories).hist()\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC902</th>\n",
       "      <th>PC903</th>\n",
       "      <th>PC904</th>\n",
       "      <th>PC905</th>\n",
       "      <th>PC906</th>\n",
       "      <th>PC907</th>\n",
       "      <th>PC908</th>\n",
       "      <th>PC909</th>\n",
       "      <th>PC910</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.397675</td>\n",
       "      <td>-4.795098</td>\n",
       "      <td>5.373249</td>\n",
       "      <td>-2.135154</td>\n",
       "      <td>7.119327</td>\n",
       "      <td>2.440652</td>\n",
       "      <td>-3.581138</td>\n",
       "      <td>4.079383</td>\n",
       "      <td>3.707602</td>\n",
       "      <td>2.234122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.409734</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.297024</td>\n",
       "      <td>-0.437412</td>\n",
       "      <td>-0.080148</td>\n",
       "      <td>-0.322287</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>0.715498</td>\n",
       "      <td>-0.258683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.140221</td>\n",
       "      <td>-0.464478</td>\n",
       "      <td>-5.024959</td>\n",
       "      <td>9.539178</td>\n",
       "      <td>-1.775166</td>\n",
       "      <td>3.502482</td>\n",
       "      <td>-0.510907</td>\n",
       "      <td>14.346949</td>\n",
       "      <td>3.996232</td>\n",
       "      <td>-3.818519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320918</td>\n",
       "      <td>-0.066611</td>\n",
       "      <td>-0.040643</td>\n",
       "      <td>-0.250331</td>\n",
       "      <td>-0.233244</td>\n",
       "      <td>0.231713</td>\n",
       "      <td>-0.124945</td>\n",
       "      <td>-0.349180</td>\n",
       "      <td>0.125595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.871541</td>\n",
       "      <td>5.597351</td>\n",
       "      <td>11.488544</td>\n",
       "      <td>7.452871</td>\n",
       "      <td>-6.898003</td>\n",
       "      <td>-3.481725</td>\n",
       "      <td>-10.846242</td>\n",
       "      <td>2.058152</td>\n",
       "      <td>-1.047376</td>\n",
       "      <td>-4.726564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226873</td>\n",
       "      <td>-0.179853</td>\n",
       "      <td>-0.063761</td>\n",
       "      <td>-0.359223</td>\n",
       "      <td>-0.267931</td>\n",
       "      <td>0.154635</td>\n",
       "      <td>0.181822</td>\n",
       "      <td>-0.247028</td>\n",
       "      <td>0.131609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.020795</td>\n",
       "      <td>10.239279</td>\n",
       "      <td>-3.020818</td>\n",
       "      <td>-11.455997</td>\n",
       "      <td>-11.367851</td>\n",
       "      <td>0.428874</td>\n",
       "      <td>-4.587209</td>\n",
       "      <td>8.291891</td>\n",
       "      <td>-15.892612</td>\n",
       "      <td>1.519730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222713</td>\n",
       "      <td>-0.183024</td>\n",
       "      <td>-0.271510</td>\n",
       "      <td>-0.299876</td>\n",
       "      <td>-0.220458</td>\n",
       "      <td>0.080214</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>-0.086031</td>\n",
       "      <td>0.220149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.341826</td>\n",
       "      <td>-1.761672</td>\n",
       "      <td>16.105620</td>\n",
       "      <td>4.526057</td>\n",
       "      <td>11.993046</td>\n",
       "      <td>6.821219</td>\n",
       "      <td>-1.874611</td>\n",
       "      <td>0.899023</td>\n",
       "      <td>1.813889</td>\n",
       "      <td>-5.969777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140855</td>\n",
       "      <td>-0.191985</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>-0.049937</td>\n",
       "      <td>-0.138432</td>\n",
       "      <td>0.051414</td>\n",
       "      <td>-0.204194</td>\n",
       "      <td>-0.220258</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>-8.612847</td>\n",
       "      <td>2.074275</td>\n",
       "      <td>-2.144486</td>\n",
       "      <td>6.733838</td>\n",
       "      <td>-3.124309</td>\n",
       "      <td>5.923397</td>\n",
       "      <td>-2.323402</td>\n",
       "      <td>1.607126</td>\n",
       "      <td>-1.390174</td>\n",
       "      <td>1.046500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098006</td>\n",
       "      <td>0.478073</td>\n",
       "      <td>0.479072</td>\n",
       "      <td>0.142164</td>\n",
       "      <td>0.628079</td>\n",
       "      <td>0.057303</td>\n",
       "      <td>-0.271578</td>\n",
       "      <td>0.044412</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>-14.392629</td>\n",
       "      <td>4.360476</td>\n",
       "      <td>-6.960752</td>\n",
       "      <td>0.053297</td>\n",
       "      <td>-1.798992</td>\n",
       "      <td>5.242563</td>\n",
       "      <td>-2.890633</td>\n",
       "      <td>-2.823239</td>\n",
       "      <td>-2.290793</td>\n",
       "      <td>2.371969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550181</td>\n",
       "      <td>-0.172729</td>\n",
       "      <td>-0.059896</td>\n",
       "      <td>-0.426643</td>\n",
       "      <td>0.325227</td>\n",
       "      <td>-0.085336</td>\n",
       "      <td>-0.092925</td>\n",
       "      <td>-0.090265</td>\n",
       "      <td>-0.427306</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>0.842402</td>\n",
       "      <td>-3.675358</td>\n",
       "      <td>-10.761197</td>\n",
       "      <td>-4.450120</td>\n",
       "      <td>1.342692</td>\n",
       "      <td>2.580862</td>\n",
       "      <td>-2.998616</td>\n",
       "      <td>-3.296310</td>\n",
       "      <td>-2.195648</td>\n",
       "      <td>-8.946582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>-0.290936</td>\n",
       "      <td>0.448635</td>\n",
       "      <td>-0.228667</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>-0.312746</td>\n",
       "      <td>-0.204022</td>\n",
       "      <td>0.059866</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>-13.864613</td>\n",
       "      <td>1.804252</td>\n",
       "      <td>-5.331252</td>\n",
       "      <td>-0.211287</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>7.135127</td>\n",
       "      <td>-1.762064</td>\n",
       "      <td>-8.790791</td>\n",
       "      <td>-4.410820</td>\n",
       "      <td>-1.813151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280404</td>\n",
       "      <td>0.410348</td>\n",
       "      <td>-0.007257</td>\n",
       "      <td>-0.124706</td>\n",
       "      <td>0.097344</td>\n",
       "      <td>0.229737</td>\n",
       "      <td>0.209323</td>\n",
       "      <td>-0.586062</td>\n",
       "      <td>-0.261179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>-3.278101</td>\n",
       "      <td>-8.846529</td>\n",
       "      <td>-6.218052</td>\n",
       "      <td>7.929351</td>\n",
       "      <td>-3.870673</td>\n",
       "      <td>-6.503059</td>\n",
       "      <td>-2.898830</td>\n",
       "      <td>-3.009331</td>\n",
       "      <td>-1.582552</td>\n",
       "      <td>-7.735914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166253</td>\n",
       "      <td>1.140345</td>\n",
       "      <td>0.379049</td>\n",
       "      <td>0.226738</td>\n",
       "      <td>0.412089</td>\n",
       "      <td>0.126420</td>\n",
       "      <td>-0.024155</td>\n",
       "      <td>0.563638</td>\n",
       "      <td>-0.522040</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4442 rows × 911 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1        PC2        PC3        PC4        PC5       PC6  \\\n",
       "0      4.397675  -4.795098   5.373249  -2.135154   7.119327  2.440652   \n",
       "1     -5.140221  -0.464478  -5.024959   9.539178  -1.775166  3.502482   \n",
       "2     -2.871541   5.597351  11.488544   7.452871  -6.898003 -3.481725   \n",
       "3     17.020795  10.239279  -3.020818 -11.455997 -11.367851  0.428874   \n",
       "4      6.341826  -1.761672  16.105620   4.526057  11.993046  6.821219   \n",
       "...         ...        ...        ...        ...        ...       ...   \n",
       "4437  -8.612847   2.074275  -2.144486   6.733838  -3.124309  5.923397   \n",
       "4438 -14.392629   4.360476  -6.960752   0.053297  -1.798992  5.242563   \n",
       "4439   0.842402  -3.675358 -10.761197  -4.450120   1.342692  2.580862   \n",
       "4440 -13.864613   1.804252  -5.331252  -0.211287   0.800797  7.135127   \n",
       "4441  -3.278101  -8.846529  -6.218052   7.929351  -3.870673 -6.503059   \n",
       "\n",
       "            PC7        PC8        PC9      PC10  ...     PC902     PC903  \\\n",
       "0     -3.581138   4.079383   3.707602  2.234122  ... -0.409734  0.047945   \n",
       "1     -0.510907  14.346949   3.996232 -3.818519  ...  0.320918 -0.066611   \n",
       "2    -10.846242   2.058152  -1.047376 -4.726564  ... -0.226873 -0.179853   \n",
       "3     -4.587209   8.291891 -15.892612  1.519730  ... -0.222713 -0.183024   \n",
       "4     -1.874611   0.899023   1.813889 -5.969777  ...  0.140855 -0.191985   \n",
       "...         ...        ...        ...       ...  ...       ...       ...   \n",
       "4437  -2.323402   1.607126  -1.390174  1.046500  ... -0.098006  0.478073   \n",
       "4438  -2.890633  -2.823239  -2.290793  2.371969  ...  0.550181 -0.172729   \n",
       "4439  -2.998616  -3.296310  -2.195648 -8.946582  ...  0.395500 -0.290936   \n",
       "4440  -1.762064  -8.790791  -4.410820 -1.813151  ...  0.280404  0.410348   \n",
       "4441  -2.898830  -3.009331  -1.582552 -7.735914  ...  0.166253  1.140345   \n",
       "\n",
       "         PC904     PC905     PC906     PC907     PC908     PC909     PC910  \\\n",
       "0     0.297024 -0.437412 -0.080148 -0.322287 -0.030384  0.715498 -0.258683   \n",
       "1    -0.040643 -0.250331 -0.233244  0.231713 -0.124945 -0.349180  0.125595   \n",
       "2    -0.063761 -0.359223 -0.267931  0.154635  0.181822 -0.247028  0.131609   \n",
       "3    -0.271510 -0.299876 -0.220458  0.080214  0.001298 -0.086031  0.220149   \n",
       "4    -0.028284 -0.049937 -0.138432  0.051414 -0.204194 -0.220258  0.126764   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4437  0.479072  0.142164  0.628079  0.057303 -0.271578  0.044412  0.019006   \n",
       "4438 -0.059896 -0.426643  0.325227 -0.085336 -0.092925 -0.090265 -0.427306   \n",
       "4439  0.448635 -0.228667  0.019310 -0.312746 -0.204022  0.059866  0.065772   \n",
       "4440 -0.007257 -0.124706  0.097344  0.229737  0.209323 -0.586062 -0.261179   \n",
       "4441  0.379049  0.226738  0.412089  0.126420 -0.024155  0.563638 -0.522040   \n",
       "\n",
       "      Label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "4437      3  \n",
       "4438      3  \n",
       "4439      3  \n",
       "4440      3  \n",
       "4441      3  \n",
       "\n",
       "[4442 rows x 911 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_train = df_train_filtered.drop(columns=['Image_Path', 'Label'])\n",
    "y_train = df_train_filtered['Label']\n",
    "X_test = df_test_filtered.drop(columns=['Image_Path', 'Label'])\n",
    "y_test = df_test_filtered['Label']\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=0.98)  \n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Create new DataFrames with PCA components\n",
    "df_train_pca = pd.DataFrame(X_train_pca, columns=[f'PC{i+1}' for i in range(X_train_pca.shape[1])])\n",
    "df_train_pca['Label'] = y_train\n",
    "\n",
    "df_test_pca = pd.DataFrame(X_test_pca, columns=[f'PC{i+1}' for i in range(X_test_pca.shape[1])])\n",
    "df_test_pca['Label'] = y_test\n",
    "\n",
    "df_train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = df_train_pca.drop(columns=['Label'])\n",
    "y_train  = df_train_pca['Label']\n",
    "\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {'max_features': [None, 'sqrt', 'log2'],\n",
    "              'ccp_alpha': [.001, .0001, 0.00001],\n",
    "              'max_depth' : [6, 9, 11, 14, 16],\n",
    "              'min_samples_split': [2, 3, 5, 6],\n",
    "              'min_samples_leaf': [1, 2, 3, 4],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree classifier\n",
    "tree_clas = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "clf_GS = GridSearchCV(estimator=tree_clas, param_grid=param_grid, cv=5, verbose=True)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "\n",
    "best_params = clf_GS.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=1e-05, criterion=&#x27;entropy&#x27;, max_depth=14,\n",
       "                       min_samples_split=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(ccp_alpha=1e-05, criterion=&#x27;entropy&#x27;, max_depth=14,\n",
       "                       min_samples_split=6)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=1e-05, criterion='entropy', max_depth=14,\n",
       "                       min_samples_split=6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Plot the decision tree with the best hyperparameters\n",
    "# plt.figure(figsize=(40, 30))  # Adjust the figure size as needed\n",
    "# plot_tree(best_dt_classifier, \n",
    "#           feature_names=X_train.columns, \n",
    "#           class_names=['jerry', 'tom', 'tom_jerry_0', 'tom_jerry_1'], \n",
    "#           filled=True,\n",
    "#           fontsize=14)  # Adjust the fontsize parameter as needed\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'max_features': None, 'ccp_alpha': 1e-05, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Accuracy: 0.980414227825304\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1007\n",
      "           1       0.99      0.99      0.99      1559\n",
      "           2       0.98      0.98      0.98      1237\n",
      "           3       0.97      0.95      0.96       639\n",
      "\n",
      "    accuracy                           0.98      4442\n",
      "   macro avg       0.98      0.98      0.98      4442\n",
      "weighted avg       0.98      0.98      0.98      4442\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 982    2   15    8]\n",
      " [   4 1546    2    7]\n",
      " [   9    9 1218    1]\n",
      " [   8   11   11  609]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameters:\", best_params)\n",
    "X_test = df_train_pca.drop(columns=['Label'])\n",
    "y_test = df_train_pca['Label']\n",
    "\n",
    "# Predict the labels for test data\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in a csv the best Decision Tree Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_df = pd.DataFrame.from_dict([best_params])\n",
    "best_params_df.to_csv('./hyperparams/best_dt_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProyectoIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
